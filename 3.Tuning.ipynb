{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "299f72bd",
   "metadata": {},
   "source": [
    "#### 1. Load imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8fe96c1-bb30-4a44-860a-98ec4326e74f",
   "metadata": {
    "height": 151
   },
   "outputs": [],
   "source": [
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.server import ServerApp, ServerConfig\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset\n",
    "\n",
    "from utils3 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827e9149",
   "metadata": {},
   "source": [
    "#### 2. Prepare the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c127d303",
   "metadata": {},
   "source": [
    "* Prepare data using Flower Datasets.\n",
    "\n",
    "Use `flwr-datasets` that provides with a Federated Dataset abstraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07bf7905-111d-4cdc-9f65-9883b8ccf393",
   "metadata": {
    "height": 219
   },
   "outputs": [],
   "source": [
    "def load_data(partition_id):\n",
    "    fds = FederatedDataset(dataset=\"mnist\", partitioners={\"train\": 5})\n",
    "    partition = fds.load_partition(partition_id)\n",
    "\n",
    "    traintest = partition.train_test_split(test_size=0.2, seed=42)\n",
    "    traintest = traintest.with_transform(normalize)\n",
    "    trainset, testset = traintest[\"train\"], traintest[\"test\"]\n",
    "\n",
    "    trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "    testloader = DataLoader(testset, batch_size=64)\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7905e136",
   "metadata": {},
   "source": [
    "#### 3. Clients configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68400707",
   "metadata": {},
   "source": [
    "* Define fit_config.\n",
    "\n",
    "Flower can send configuration values to clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16125466-5b8b-4c57-956c-542cd0b8f4a2",
   "metadata": {
    "height": 117
   },
   "outputs": [],
   "source": [
    "def fit_config(server_round: int):\n",
    "    config_dict = {\n",
    "        \"local_epochs\": 2 if server_round < 3 else 5,\n",
    "    }\n",
    "    return config_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eadf6e5",
   "metadata": {},
   "source": [
    "* The FedAvg strategy in the Server Function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a09f1649-c5d8-44d1-9777-0270f2864723",
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "net = SimpleModel()\n",
    "params = ndarrays_to_parameters(get_weights(net))\n",
    "\n",
    "def server_fn(context: Context):\n",
    "    strategy = FedAvg(\n",
    "        min_fit_clients=5,\n",
    "        fraction_evaluate=0.0,\n",
    "        initial_parameters=params,\n",
    "        on_fit_config_fn=fit_config,  # <- NEW\n",
    "    )\n",
    "    config=ServerConfig(num_rounds=3)\n",
    "    return ServerAppComponents(\n",
    "        strategy=strategy,\n",
    "        config=config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6da428f",
   "metadata": {},
   "source": [
    "* Define an instance of ServerApp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30e24c28-4420-4432-9cbd-ab0773215c36",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "server = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c3feb",
   "metadata": {},
   "source": [
    "* Define FlowerClient.\n",
    "\n",
    "The client side receives the configuration dictionary in the `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0918d659-8c35-4cf8-a2fb-aaa0e8475fde",
   "metadata": {
    "height": 355
   },
   "outputs": [],
   "source": [
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, net, trainloader, testloader):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = testloader\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_weights(self.net, parameters)\n",
    "\n",
    "        epochs = config[\"local_epochs\"]\n",
    "        log(INFO, f\"client trains for {epochs} epochs\")\n",
    "        train_model(self.net, self.trainloader, epochs)\n",
    "\n",
    "        return get_weights(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_weights(self.net, parameters)\n",
    "        loss, accuracy = evaluate_model(self.net, self.testloader)\n",
    "        return loss, len(self.testloader), {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edac892",
   "metadata": {},
   "source": [
    "* Create the Client Function and the Client App."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79093643-032d-41b3-a544-dab4362acaac",
   "metadata": {
    "height": 168
   },
   "outputs": [],
   "source": [
    "def client_fn(context: Context) -> Client:\n",
    "    net = SimpleModel()\n",
    "    partition_id = int(context.node_config[\"partition-id\"])\n",
    "    trainloader, testloader = load_data(partition_id=partition_id)\n",
    "    return FlowerClient(net, trainloader, testloader).to_client()\n",
    "\n",
    "\n",
    "client = ClientApp(client_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb8b07a",
   "metadata": {},
   "source": [
    "* Run Client and Server apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "852baa38-2284-44f7-81e7-4106959094cd",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m: Starting Flower ServerApp, config: num_rounds=3, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [INIT]\n",
      "\u001b[92mINFO \u001b[0m: Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m: Evaluating initial global parameters\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 5 clients (out of 5)\n",
      "Downloading builder script: 100%|██████████| 3.98k/3.98k [00:00<00:00, 27.8MB/s]\n",
      "Downloading readme: 100%|██████████| 6.83k/6.83k [00:00<00:00, 34.6MB/s]\n",
      "Downloading data:   0%|          | 0.00/9.91M [00:00<?, ?B/s]\n",
      "Downloading data: 100%|██████████| 9.91M/9.91M [00:00<00:00, 85.1MB/s]\n",
      "Downloading data: 100%|██████████| 28.9k/28.9k [00:00<00:00, 9.08MB/s]\n",
      "Downloading data: 100%|██████████| 1.65M/1.65M [00:00<00:00, 51.8MB/s]\n",
      "Downloading data: 100%|██████████| 4.54k/4.54k [00:00<00:00, 16.6MB/s]\n",
      "Generating train split:   0%|          | 0/60000 [00:00<?, ? examples/s]\n",
      "Generating train split:   1%|          | 410/60000 [00:00<00:15, 3838.21 examples/s]\n",
      "Generating train split:   2%|▏         | 990/60000 [00:00<00:11, 4954.42 examples/s]\n",
      "Generating train split:   3%|▎         | 1761/60000 [00:00<00:09, 6181.52 examples/s]\n",
      "Generating train split:   4%|▍         | 2454/60000 [00:00<00:08, 6468.53 examples/s]\n",
      "Generating train split:   6%|▌         | 3324/60000 [00:00<00:09, 6163.03 examples/s]\n",
      "Generating train split:   7%|▋         | 4000/60000 [00:00<00:08, 6315.84 examples/s]\n",
      "Generating train split:   8%|▊         | 4831/60000 [00:00<00:07, 6914.60 examples/s]\n",
      "Generating train split:  10%|▉         | 5814/60000 [00:00<00:08, 6765.64 examples/s]\n",
      "Generating train split:  11%|█         | 6559/60000 [00:01<00:07, 6948.39 examples/s]\n",
      "Generating train split:  13%|█▎        | 7602/60000 [00:01<00:07, 6947.85 examples/s]\n",
      "Generating train split:  14%|█▍        | 8414/60000 [00:01<00:07, 7208.59 examples/s]\n",
      "Generating train split:  16%|█▌        | 9513/60000 [00:01<00:06, 7248.34 examples/s]\n",
      "Generating train split:  17%|█▋        | 10308/60000 [00:01<00:06, 7424.91 examples/s]\n",
      "Generating train split:  19%|█▉        | 11429/60000 [00:01<00:06, 7437.92 examples/s]\n",
      "Generating train split:  20%|██        | 12189/60000 [00:01<00:06, 7475.99 examples/s]\n",
      "Generating train split:  22%|██▏       | 12969/60000 [00:01<00:06, 7558.99 examples/s]\n",
      "Generating train split:  23%|██▎       | 13751/60000 [00:01<00:06, 7627.19 examples/s]\n",
      "Generating train split:  25%|██▍       | 14873/60000 [00:02<00:05, 7568.78 examples/s]\n",
      "Generating train split:  27%|██▋       | 15920/60000 [00:02<00:05, 7360.06 examples/s]\n",
      "Generating train split:  28%|██▊       | 16679/60000 [00:02<00:05, 7414.57 examples/s]\n",
      "Generating train split:  30%|██▉       | 17740/60000 [00:02<00:05, 7204.43 examples/s]\n",
      "Generating train split:  31%|███       | 18504/60000 [00:02<00:05, 7308.04 examples/s]\n",
      "Generating train split:  32%|███▏      | 19247/60000 [00:02<00:05, 7338.86 examples/s]\n",
      "Generating train split:  33%|███▎      | 20025/60000 [00:02<00:05, 7453.46 examples/s]\n",
      "Generating train split:  35%|███▌      | 21140/60000 [00:02<00:05, 7442.66 examples/s]\n",
      "Generating train split:  37%|███▋      | 21912/60000 [00:03<00:05, 7509.62 examples/s]\n",
      "Generating train split:  38%|███▊      | 23000/60000 [00:03<00:05, 7393.51 examples/s]\n",
      "Generating train split:  40%|████      | 24000/60000 [00:03<00:06, 5269.78 examples/s]\n",
      "Generating train split:  41%|████▏     | 24837/60000 [00:03<00:05, 5861.85 examples/s]\n",
      "Generating train split:  43%|████▎     | 25651/60000 [00:03<00:05, 6348.07 examples/s]\n",
      "Generating train split:  44%|████▍     | 26453/60000 [00:03<00:04, 6738.17 examples/s]\n",
      "Generating train split:  45%|████▌     | 27254/60000 [00:03<00:04, 7053.45 examples/s]\n",
      "Generating train split:  47%|████▋     | 28055/60000 [00:04<00:04, 7303.14 examples/s]\n",
      "Generating train split:  48%|████▊     | 28890/60000 [00:04<00:04, 7585.51 examples/s]\n",
      "Generating train split:  50%|█████     | 30055/60000 [00:04<00:03, 7649.67 examples/s]\n",
      "Generating train split:  51%|█████▏    | 30878/60000 [00:04<00:03, 7799.57 examples/s]\n",
      "Generating train split:  53%|█████▎    | 31689/60000 [00:04<00:03, 7882.60 examples/s]\n",
      "Generating train split:  55%|█████▍    | 32902/60000 [00:04<00:03, 7953.56 examples/s]\n",
      "Generating train split:  57%|█████▋    | 34075/60000 [00:04<00:03, 7902.65 examples/s]\n",
      "Generating train split:  58%|█████▊    | 34907/60000 [00:04<00:03, 8002.30 examples/s]\n",
      "Generating train split:  60%|██████    | 36097/60000 [00:05<00:02, 7974.27 examples/s]\n",
      "Generating train split:  62%|██████▏   | 36913/60000 [00:05<00:02, 8018.99 examples/s]\n",
      "Generating train split:  63%|██████▎   | 38091/60000 [00:05<00:02, 7960.36 examples/s]\n",
      "Generating train split:  65%|██████▍   | 38921/60000 [00:05<00:02, 8042.54 examples/s]\n",
      "Generating train split:  67%|██████▋   | 40117/60000 [00:05<00:02, 8012.91 examples/s]\n",
      "Generating train split:  68%|██████▊   | 40946/60000 [00:05<00:02, 8077.61 examples/s]\n",
      "Generating train split:  70%|███████   | 42137/60000 [00:05<00:02, 8025.36 examples/s]\n",
      "Generating train split:  72%|███████▏  | 42955/60000 [00:05<00:02, 8063.19 examples/s]\n",
      "Generating train split:  74%|███████▎  | 44156/60000 [00:06<00:01, 8041.84 examples/s]\n",
      "Generating train split:  75%|███████▍  | 44984/60000 [00:06<00:01, 8098.37 examples/s]\n",
      "Generating train split:  77%|███████▋  | 46148/60000 [00:06<00:01, 7975.79 examples/s]\n",
      "Generating train split:  78%|███████▊  | 46972/60000 [00:06<00:01, 8039.83 examples/s]\n",
      "Generating train split:  80%|████████  | 48177/60000 [00:06<00:01, 8035.16 examples/s]\n",
      "Generating train split:  82%|████████▏ | 49000/60000 [00:06<00:01, 8029.09 examples/s]\n",
      "Generating train split:  83%|████████▎ | 49831/60000 [00:06<00:01, 8099.83 examples/s]\n",
      "Generating train split:  84%|████████▍ | 50645/60000 [00:06<00:01, 8110.50 examples/s]\n",
      "Generating train split:  86%|████████▋ | 51859/60000 [00:06<00:01, 8099.19 examples/s]\n",
      "Generating train split:  88%|████████▊ | 52675/60000 [00:07<00:00, 8114.71 examples/s]\n",
      "Generating train split:  90%|████████▉ | 53909/60000 [00:07<00:00, 8150.34 examples/s]\n",
      "Generating train split:  92%|█████████▏| 55095/60000 [00:07<00:00, 8066.51 examples/s]\n",
      "Generating train split:  93%|█████████▎| 55923/60000 [00:07<00:00, 8115.37 examples/s]\n",
      "Generating train split:  95%|█████████▌| 57104/60000 [00:07<00:00, 8029.34 examples/s]\n",
      "Generating train split:  97%|█████████▋| 57929/60000 [00:07<00:00, 8080.98 examples/s]\n",
      "Generating train split:  99%|█████████▊| 59113/60000 [00:07<00:00, 8012.25 examples/s]\n",
      "Generating train split: 100%|██████████| 60000/60000 [00:07<00:00, 7501.79 examples/s]\n",
      "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]\n",
      "Generating test split:   8%|▊         | 778/10000 [00:00<00:01, 7756.78 examples/s]\n",
      "Generating test split:  16%|█▌        | 1579/10000 [00:00<00:01, 7900.52 examples/s]\n",
      "Generating test split:  24%|██▍       | 2413/10000 [00:00<00:00, 7997.57 examples/s]\n",
      "Generating test split:  32%|███▏      | 3224/10000 [00:00<00:00, 8039.11 examples/s]\n",
      "Generating test split:  45%|████▍     | 4451/10000 [00:00<00:00, 8096.85 examples/s]\n",
      "Generating test split:  57%|█████▋    | 5666/10000 [00:00<00:00, 8093.43 examples/s]\n",
      "Generating test split:  69%|██████▉   | 6888/10000 [00:00<00:00, 8110.32 examples/s]\n",
      "Generating test split:  77%|███████▋  | 7700/10000 [00:00<00:00, 8111.40 examples/s]\n",
      "Generating test split:  89%|████████▉ | 8889/10000 [00:01<00:00, 8042.81 examples/s]\n",
      "Generating test split: 100%|██████████| 10000/10000 [00:01<00:00, 8039.69 examples/s]\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=493)\u001b[0m \u001b[92mINFO \u001b[0m: client trains for 2 epochs\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=493)\u001b[0m \u001b[92mINFO \u001b[0m: client trains for 2 epochs\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=493)\u001b[0m \u001b[92mINFO \u001b[0m: client trains for 2 epochs\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=493)\u001b[0m \u001b[92mINFO \u001b[0m: client trains for 2 epochs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=493)\u001b[0m \u001b[92mINFO \u001b[0m: client trains for 5 epochs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=495)\u001b[0m \u001b[92mINFO \u001b[0m: client trains for 5 epochs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m: Run finished 3 round(s) in 71.53s\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=493)\u001b[0m \u001b[92mINFO \u001b[0m: client trains for 5 epochs\n"
     ]
    }
   ],
   "source": [
    "run_simulation(server_app=server,\n",
    "               client_app=client,\n",
    "               num_supernodes=5,\n",
    "               backend_config=backend_setup\n",
    "               )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
